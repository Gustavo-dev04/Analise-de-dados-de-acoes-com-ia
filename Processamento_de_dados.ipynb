{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ITqHnLiMYAs1PuFDjLUe-BK_icWKcc4c",
      "authorship_tag": "ABX9TyPNRAe12m7Rfl0oI/q4OLlY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavo-dev04/Analise-de-dados-de-acoes-com-ia/blob/main/Processamento_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå IMPORTA√á√ïES ESSENCIAIS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# üìå CONFIGURA√á√ïES\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (18, 9)\n",
        "\n",
        "# Configura√ß√µes\n",
        "SYMBOL = 'NVDA'\n",
        "DAYS_TO_FETCH = 365 * 1  # 2 anos de dados\n",
        "TEST_SIZE = 0.2\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 50000\n",
        "VOLATILITY_WINDOW = 20  # Janela para c√°lculo de volatilidade\n",
        "\n",
        "# üìå CONFIGURA√á√ÉO SEGURA DA API KEY (Google Colab)\n",
        "try:\n",
        "    NEWS_API_KEY = userdata.get('NEWS_API_KEY')\n",
        "    print(\"‚úÖ API Key carregada com sucesso dos Secrets do Colab\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è AVISO: {str(e)}\")\n",
        "    print(\"‚ö†Ô∏è Configure sua API Key nos Secrets do Colab (barra lateral > Secrets)\")\n",
        "    NEWS_API_KEY = input(\"Cole temporariamente sua API Key da NewsAPI: \").strip()\n",
        "    if not NEWS_API_KEY:\n",
        "        print(\"‚ö†Ô∏è Usando modo simulado - funcionalidades limitadas\")\n",
        "        NEWS_API_KEY = None\n",
        "\n",
        "# Baixa recursos do NLTK\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# ======================\n",
        "# üìå 1. AN√ÅLISE DE NOT√çCIAS EM TEMPO REAL\n",
        "# ======================\n",
        "class NewsSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "        self.session = requests.Session()\n",
        "\n",
        "    def fetch_real_news(self, query='NVIDIA', language='en', page_size=1000):\n",
        "        \"\"\"Busca not√≠cias reais com fallback simulado\"\"\"\n",
        "        if not NEWS_API_KEY:\n",
        "            print(\"‚ö†Ô∏è Modo simulado ativado (sem API Key configurada)\")\n",
        "            return self._get_simulated_news()\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nüîç Buscando not√≠cias reais sobre {query}...\")\n",
        "            url = f\"https://newsapi.org/v2/everything?q={query}&language={language}&pageSize={page_size}&apiKey={NEWS_API_KEY}\"\n",
        "            response = self.session.get(url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if data['status'] != 'ok':\n",
        "                print(f\"‚ö†Ô∏è Problema na API: {data.get('message', 'Erro desconhecido')}\")\n",
        "                return self._get_simulated_news()\n",
        "\n",
        "            return data['articles']\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro ao acessar API: {str(e)}\")\n",
        "            return self._get_simulated_news()\n",
        "\n",
        "    def _get_simulated_news(self):\n",
        "        \"\"\"Fornece dados simulados quando a API falha\"\"\"\n",
        "        return [\n",
        "            {'title': 'NVIDIA anuncia avan√ßos em IA com novos chips', 'content': 'Inova√ß√£o revolucion√°ria no mercado', 'publishedAt': datetime.now().isoformat()},\n",
        "            {'title': 'A√ß√µes da NVIDIA em alta ap√≥s resultados positivos', 'content': 'Crescimento acima das expectativas', 'publishedAt': datetime.now().isoformat()},\n",
        "            {'title': 'NVIDIA enfrenta desafios na cadeia de suprimentos', 'content': 'Problemas log√≠sticos afetam produ√ß√£o', 'publishedAt': datetime.now().isoformat()}\n",
        "        ]\n",
        "\n",
        "    def analyze_sentiment(self, articles):\n",
        "        \"\"\"Analisa o sentimento das not√≠cias\"\"\"\n",
        "        if not articles:\n",
        "            return 0.0  # Retorno neutro se n√£o houver not√≠cias\n",
        "\n",
        "        sentiments = []\n",
        "        print(\"\\nüì∞ An√°lise de Sentimento das Not√≠cias:\")\n",
        "\n",
        "        for article in articles[:1000]:  # Analisa apenas as 5 primeiras\n",
        "            text = f\"{article.get('title', '')} {article.get('content', '')}\"\n",
        "            vs = self.analyzer.polarity_scores(text)\n",
        "            compound = vs['compound']\n",
        "\n",
        "            # Classifica√ß√£o visual\n",
        "            if compound >= 0.05:\n",
        "                emoji = \"üìà\"\n",
        "                sentiment = \"POSITIVO\"\n",
        "            elif compound <= -0.05:\n",
        "                emoji = \"üìâ\"\n",
        "                sentiment = \"NEGATIVO\"\n",
        "            else:\n",
        "                emoji = \"‚ûñ\"\n",
        "                sentiment = \"NEUTRO\"\n",
        "\n",
        "            print(f\"{emoji} {sentiment} ({compound:.2f}): {article.get('title','')[:60]}...\")\n",
        "            sentiments.append(compound)\n",
        "\n",
        "        avg_sentiment = np.mean(sentiments) if sentiments else 0.0\n",
        "        print(f\"\\nüîç Sentimento M√©dio: {avg_sentiment:.2f} (Escala: -1 a 1)\")\n",
        "        return avg_sentiment\n",
        "\n",
        "# ======================\n",
        "# üìå 2. MODELO DE PREVIS√ÉO DE PRE√áOS\n",
        "# ======================\n",
        "class StockPredictor:\n",
        "    def __init__(self):\n",
        "        self.learning_rate = LEARNING_RATE\n",
        "        self.epochs = EPOCHS\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.scaler = RobustScaler()\n",
        "        self.feature_cols = [\n",
        "            'close', 'volume', 'ma_5', 'ma_20',\n",
        "            'volatility_20', 'trend', 'sentiment'\n",
        "        ]\n",
        "        self.news_analyzer = NewsSentimentAnalyzer()\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"Prepara os dados para o modelo garantindo consist√™ncia\"\"\"\n",
        "        try:\n",
        "            # Feature Engineering\n",
        "            df['return'] = df['close'].pct_change()\n",
        "\n",
        "            # M√©dias M√≥veis\n",
        "            for window in [5, 20]:\n",
        "                df[f'ma_{window}'] = df['close'].rolling(window).mean()\n",
        "\n",
        "            # Volatilidade\n",
        "            df['volatility_20'] = df['return'].rolling(VOLATILITY_WINDOW).std()\n",
        "\n",
        "            # Tend√™ncia\n",
        "            df['trend'] = (df['close'] > df['ma_20']).astype(int)\n",
        "\n",
        "            # An√°lise de Sentimento\n",
        "            df['sentiment'] = self.news_analyzer.analyze_sentiment(\n",
        "                self.news_analyzer.fetch_real_news()\n",
        "            )\n",
        "\n",
        "            # Remove valores NA\n",
        "            df = df.dropna()\n",
        "\n",
        "            # Garante alinhamento correto entre X e y\n",
        "            X = df[self.feature_cols].iloc[:-1]  # Remove a √∫ltima linha para X\n",
        "            y = df['close'].shift(-1).dropna()   # Remove a primeira linha para y\n",
        "\n",
        "            # Verifica√ß√£o de consist√™ncia\n",
        "            if len(X) != len(y):\n",
        "                raise ValueError(f\"N√∫mero de amostras inconsistente: X={len(X)}, y={len(y)}\")\n",
        "\n",
        "            # Normaliza√ß√£o\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            # Divis√£o Treino-Teste Temporal\n",
        "            split_idx = int(len(X) * (1 - TEST_SIZE))\n",
        "            X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            # Adiciona coluna de bias\n",
        "            X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "            X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "            return X_train, X_test, y_train, y_test, df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro na prepara√ß√£o: {str(e)}\")\n",
        "            # Fallback sem sentimento se necess√°rio\n",
        "            self.feature_cols = [col for col in self.feature_cols if col != 'sentiment']\n",
        "            return self.prepare_data(df)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        \"\"\"Treina o modelo com Gradiente Descendente\"\"\"\n",
        "        try:\n",
        "            n_samples, n_features = X.shape\n",
        "            self.weights = np.zeros(n_features)\n",
        "            self.bias = 0\n",
        "            cost_history = []\n",
        "\n",
        "            for epoch in range(self.epochs):\n",
        "                y_pred = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "                # Gradientes\n",
        "                dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
        "                db = (1/n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "                # Atualiza√ß√£o\n",
        "                self.weights -= self.learning_rate * dw\n",
        "                self.bias -= self.learning_rate * db\n",
        "\n",
        "                # C√°lculo de Custo\n",
        "                cost = np.mean((y_pred - y)**2)\n",
        "                cost_history.append(cost)\n",
        "\n",
        "                if epoch % 1000 == 0:\n",
        "                    print(f\"√âpoca {epoch}: MSE = {cost:.4f}\")\n",
        "\n",
        "            return cost_history\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Erro no treinamento: {str(e)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Faz previs√µes\"\"\"\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"Avalia o modelo com garantia de alinhamento\"\"\"\n",
        "        try:\n",
        "            y_pred = self.predict(X_test)\n",
        "\n",
        "            # Cria Series com mesmo √≠ndice para alinhamento\n",
        "            y_pred_series = pd.Series(y_pred, index=y_test.index)\n",
        "\n",
        "            # M√©tricas\n",
        "            mae = mean_absolute_error(y_test, y_pred_series)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, y_pred_series))\n",
        "            r2 = r2_score(y_test, y_pred_series)\n",
        "\n",
        "            # Plot\n",
        "            plt.figure(figsize=(18, 9))\n",
        "            plt.plot(y_test.values, label='Real', color='#1f77b4', linewidth=2)\n",
        "            plt.plot(y_pred_series.values, label='Previsto', color='#ff7f0e', linestyle='--')\n",
        "\n",
        "            plt.title(f'Desempenho do Modelo (MAE: ${mae:.2f}, R¬≤: {r2:.2%})', fontsize=16)\n",
        "            plt.xlabel('Dias')\n",
        "            plt.ylabel('Pre√ßo ($)')\n",
        "            plt.legend()\n",
        "            plt.grid(alpha=0.3)\n",
        "            plt.show()\n",
        "\n",
        "            return {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Erro na avalia√ß√£o: {str(e)}\")\n",
        "\n",
        "    def forecast(self, df, days=7):\n",
        "        \"\"\"Previs√£o para os pr√≥ximos dias com consist√™ncia\"\"\"\n",
        "        try:\n",
        "            forecasts = []\n",
        "            dates = []\n",
        "            last_data = df[self.feature_cols].iloc[-1:].copy()\n",
        "\n",
        "            for i in range(1, days+1):\n",
        "                # Prepara dados\n",
        "                data_scaled = self.scaler.transform(last_data)\n",
        "                data_scaled = np.c_[np.ones(data_scaled.shape[0]), data_scaled]\n",
        "\n",
        "                # Previs√£o\n",
        "                pred = self.predict(data_scaled)[0]\n",
        "                forecasts.append(pred)\n",
        "                dates.append(df.index[-1] + timedelta(days=i))\n",
        "\n",
        "                # Atualiza para pr√≥xima previs√£o\n",
        "                new_row = last_data.copy()\n",
        "                new_row['close'] = pred\n",
        "\n",
        "                # Atualiza indicadores t√©cnicos\n",
        "                new_row['ma_5'] = np.mean([*df['close'].iloc[-4:], pred])\n",
        "                new_row['ma_20'] = np.mean([*df['close'].iloc[-19:], pred])\n",
        "                new_row['volatility_20'] = df['volatility_20'].iloc[-1]  # Mant√©m √∫ltima volatilidade conhecida\n",
        "                new_row['trend'] = 1 if pred > new_row['ma_20'].values[0] else 0\n",
        "\n",
        "                # Mant√©m o mesmo sentimento\n",
        "                if 'sentiment' in new_row.columns:\n",
        "                    new_row['sentiment'] = last_data['sentiment'].values[0]\n",
        "\n",
        "                last_data = new_row\n",
        "\n",
        "            # Cria DataFrame com previs√µes\n",
        "            forecast_df = pd.DataFrame({\n",
        "                'date': dates,\n",
        "                'forecast': forecasts\n",
        "            }).set_index('date')\n",
        "\n",
        "            # Plot\n",
        "            plt.figure(figsize=(18, 9))\n",
        "            plt.plot(df['close'].iloc[-30:], label='Hist√≥rico (30 dias)', marker='o')\n",
        "            plt.plot(forecast_df['forecast'], label=f'Previs√£o ({days} dias)',\n",
        "                    color='red', linestyle='--', marker='o')\n",
        "            plt.title(f'Previs√£o para {SYMBOL}', fontsize=16)\n",
        "            plt.xlabel('Data')\n",
        "            plt.ylabel('Pre√ßo ($)')\n",
        "            plt.legend()\n",
        "            plt.grid(alpha=0.3)\n",
        "            plt.show()\n",
        "\n",
        "            return forecast_df\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Erro na previs√£o: {str(e)}\")\n",
        "\n",
        "# ======================\n",
        "# üìå 3. EXECU√á√ÉO PRINCIPAL\n",
        "# ======================\n",
        "def main():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"=== PREVIS√ÉO DE A√á√ïES {SYMBOL} COM AN√ÅLISE DE SENTIMENTOS ===\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "\n",
        "    try:\n",
        "        # 1. Baixar dados hist√≥ricos\n",
        "        print(\"üìä Baixando dados hist√≥ricos...\")\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=DAYS_TO_FETCH)\n",
        "        df = yf.download(SYMBOL, start=start_date, end=end_date)[['Close', 'Volume']]\n",
        "        df.columns = ['close', 'volume']\n",
        "        print(f\"‚úÖ Dados de {df.index[0].date()} a {df.index[-1].date()}\")\n",
        "        print(f\"üìà √öltimo pre√ßo: ${df['close'].iloc[-1]:.2f}\\n\")\n",
        "\n",
        "        # 2. Preparar modelo\n",
        "        print(\"üß† Preparando modelo...\")\n",
        "        predictor = StockPredictor()\n",
        "        X_train, X_test, y_train, y_test, df_processed = predictor.prepare_data(df)\n",
        "        print(f\"üìä Dados preparados | Treino: {len(X_train)} | Teste: {len(X_test)}\")\n",
        "\n",
        "        # 3. Treinar modelo\n",
        "        print(\"\\nüîÆ Treinando modelo...\")\n",
        "        cost_history = predictor.train(X_train, y_train)\n",
        "\n",
        "        # Plot de converg√™ncia\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(cost_history)\n",
        "        plt.title('Converg√™ncia do Treinamento')\n",
        "        plt.xlabel('√âpocas')\n",
        "        plt.ylabel('Erro (MSE)')\n",
        "        plt.show()\n",
        "\n",
        "        # 4. Avaliar modelo\n",
        "        print(\"\\nüìä Avaliando desempenho...\")\n",
        "        metrics = predictor.evaluate(X_test, y_test)\n",
        "        print(f\"\\nüîç Resultados:\")\n",
        "        print(f\"- Erro M√©dio Absoluto (MAE): ${metrics['mae']:.2f}\")\n",
        "        print(f\"- Raiz do Erro Quadr√°tico M√©dio (RMSE): ${metrics['rmse']:.2f}\")\n",
        "        print(f\"- Coeficiente de Determina√ß√£o (R¬≤): {metrics['r2']:.2%}\")\n",
        "\n",
        "        # 5. Fazer previs√µes\n",
        "        print(\"\\nüîÆ Gerando previs√µes para os pr√≥ximos 7 dias...\")\n",
        "        forecast = predictor.forecast(df_processed)\n",
        "        print(\"\\nüìà Previs√µes de Pre√ßo:\")\n",
        "        print(forecast.round(2))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Erro: {str(e)}\")\n",
        "        print(\"\\nüí° Poss√≠veis solu√ß√µes:\")\n",
        "        print(\"- Verifique sua conex√£o com a internet\")\n",
        "        print(\"- Confira se a API Key foi configurada corretamente\")\n",
        "        print(\"- Reduza o n√∫mero de √©pocas se o treinamento estiver demorando\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Verifica e instala depend√™ncias se necess√°rio\n",
        "    try:\n",
        "        import yfinance\n",
        "    except ImportError:\n",
        "        print(\"Instalando depend√™ncias necess√°rias...\")\n",
        "        !pip install yfinance nltk scikit-learn --quiet\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kC-UvnrkkJn",
        "outputId": "40b101a2-4d6d-45bf-9520-42ec6f686e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key carregada com sucesso dos Secrets do Colab\n",
            "\n",
            "==================================================\n",
            "=== PREVIS√ÉO DE A√á√ïES NVDA COM AN√ÅLISE DE SENTIMENTOS ===\n",
            "==================================================\n",
            "\n",
            "üìä Baixando dados hist√≥ricos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dados de 2024-04-03 a 2025-04-02\n",
            "üìà √öltimo pre√ßo: $110.42\n",
            "\n",
            "üß† Preparando modelo...\n",
            "\n",
            "üîç Buscando not√≠cias reais sobre NVIDIA...\n",
            "‚ö†Ô∏è Erro ao acessar API: 426 Client Error: Upgrade Required for url: https://newsapi.org/v2/everything?q=NVIDIA&language=en&pageSize=1000&apiKey=5f4f653a4023477fa7725ea18a221b5d\n",
            "\n",
            "üì∞ An√°lise de Sentimento das Not√≠cias:\n",
            "üìâ NEGATIVO (-0.30): NVIDIA anuncia avan√ßos em IA com novos chips...\n",
            "‚ûñ NEUTRO (0.00): A√ß√µes da NVIDIA em alta ap√≥s resultados positivos...\n",
            "‚ûñ NEUTRO (0.00): NVIDIA enfrenta desafios na cadeia de suprimentos...\n",
            "\n",
            "üîç Sentimento M√©dio: -0.10 (Escala: -1 a 1)\n",
            "üìä Dados preparados | Treino: 184 | Teste: 46\n",
            "\n",
            "üîÆ Treinando modelo...\n",
            "√âpoca 0: MSE = 15856.0913\n",
            "√âpoca 1000: MSE = 17.8089\n",
            "√âpoca 2000: MSE = 17.4362\n",
            "√âpoca 3000: MSE = 17.3671\n",
            "√âpoca 4000: MSE = 17.3519\n",
            "√âpoca 5000: MSE = 17.3483\n",
            "√âpoca 6000: MSE = 17.3474\n",
            "√âpoca 7000: MSE = 17.3472\n",
            "√âpoca 8000: MSE = 17.3472\n",
            "√âpoca 9000: MSE = 17.3472\n",
            "√âpoca 10000: MSE = 17.3472\n",
            "√âpoca 11000: MSE = 17.3472\n",
            "√âpoca 12000: MSE = 17.3472\n",
            "√âpoca 13000: MSE = 17.3472\n",
            "√âpoca 14000: MSE = 17.3472\n",
            "√âpoca 15000: MSE = 17.3472\n",
            "√âpoca 16000: MSE = 17.3472\n",
            "√âpoca 17000: MSE = 17.3472\n",
            "√âpoca 18000: MSE = 17.3472\n",
            "√âpoca 19000: MSE = 17.3472\n",
            "√âpoca 20000: MSE = 17.3472\n",
            "√âpoca 21000: MSE = 17.3472\n",
            "√âpoca 22000: MSE = 17.3472\n",
            "√âpoca 23000: MSE = 17.3472\n",
            "√âpoca 24000: MSE = 17.3472\n",
            "√âpoca 25000: MSE = 17.3472\n",
            "√âpoca 26000: MSE = 17.3472\n",
            "√âpoca 27000: MSE = 17.3472\n",
            "√âpoca 28000: MSE = 17.3472\n",
            "√âpoca 29000: MSE = 17.3472\n",
            "√âpoca 30000: MSE = 17.3472\n",
            "√âpoca 31000: MSE = 17.3472\n",
            "√âpoca 32000: MSE = 17.3472\n",
            "√âpoca 33000: MSE = 17.3472\n",
            "√âpoca 34000: MSE = 17.3472\n",
            "√âpoca 35000: MSE = 17.3472\n",
            "√âpoca 36000: MSE = 17.3472\n",
            "√âpoca 37000: MSE = 17.3472\n",
            "√âpoca 38000: MSE = 17.3472\n",
            "√âpoca 39000: MSE = 17.3472\n",
            "√âpoca 40000: MSE = 17.3472\n",
            "√âpoca 41000: MSE = 17.3472\n",
            "√âpoca 42000: MSE = 17.3472\n",
            "√âpoca 43000: MSE = 17.3472\n"
          ]
        }
      ]
    }
  ]
}
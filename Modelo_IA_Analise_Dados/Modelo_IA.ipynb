{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ITqHnLiMYAs1PuFDjLUe-BK_icWKcc4c",
      "authorship_tag": "ABX9TyM+W3pu+o/ScXps0giZk/sz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavo-dev04/Analise-de-dados-de-acoes-com-ia/blob/main/Modelo_IA_Analise_Dados/Modelo_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m nltk.downloader vader_lexicon\n",
        "!pip install yfinance feedparser textblob nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import feedparser\n",
        "import time\n",
        "import warnings\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (18, 9)\n",
        "\n",
        "SYMBOL = 'NVDA'\n",
        "DAYS_TO_FETCH = 365 * 5\n",
        "TEST_SIZE = 0.2\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 50000\n",
        "VOLATILITY_WINDOW = 20\n",
        "REQUEST_TIMEOUT = 15\n",
        "MIN_NEWS_ARTICLES = 5\n",
        "MAX_NEWS_ARTICLES = 10\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "\n",
        "class GoogleNewsAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})\n",
        "        self.session.timeout = REQUEST_TIMEOUT\n",
        "        self.vader = SentimentIntensityAnalyzer()\n",
        "        self.rss_url = f\"https://news.google.com/rss/search?q={SYMBOL}+stock&hl=en-US&gl=US&ceid=US:en\"\n",
        "        self.finance_terms = {\n",
        "            'positive': ['bullish', 'upgrade', 'beat', 'growth', 'raise', 'buy', 'outperform'],\n",
        "            'negative': ['bearish', 'downgrade', 'miss', 'cut', 'sell', 'underperform']\n",
        "        }\n",
        "\n",
        "    def fetch_google_news(self):\n",
        "        articles = []\n",
        "        try:\n",
        "            response = self.session.get(self.rss_url, timeout=REQUEST_TIMEOUT)\n",
        "            response.raise_for_status()\n",
        "            feed = feedparser.parse(response.text)\n",
        "            for entry in feed.entries[:MAX_NEWS_ARTICLES]:\n",
        "                pub_date = datetime.now()\n",
        "                if hasattr(entry, 'published_parsed'):\n",
        "                    pub_date = datetime(*entry.published_parsed[:6])\n",
        "                articles.append({\n",
        "                    'title': entry.title,\n",
        "                    'source': entry.source.title if hasattr(entry, 'source') else 'Google News',\n",
        "                    'date': pub_date,\n",
        "                    'url': entry.link\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro ao acessar Google News: {str(e)}\")\n",
        "        return articles\n",
        "\n",
        "    def _get_fallback_news(self):\n",
        "        trends = ['high', 'growth', 'drop', 'volatile', 'steady']\n",
        "        return [{\n",
        "            'title': f\"{SYMBOL} shows {np.random.choice(trends)} amid market {'gains' if np.random.random() > 0.5 else 'losses'}\",\n",
        "            'source': 'Market Trend',\n",
        "            'date': datetime.now(),\n",
        "            'url': ''\n",
        "        } for _ in range(MIN_NEWS_ARTICLES)]\n",
        "\n",
        "    def analyze_with_vader(self, text):\n",
        "        return self.vader.polarity_scores(text)['compound']\n",
        "\n",
        "    def analyze_with_textblob(self, text):\n",
        "        analysis = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
        "        return analysis.sentiment.p_pos - analysis.sentiment.p_neg\n",
        "\n",
        "    def analyze_finance_terms(self, text):\n",
        "        score = 0\n",
        "        text_lower = text.lower()\n",
        "        for term in self.finance_terms['positive']:\n",
        "            if term in text_lower:\n",
        "                score += 0.2\n",
        "        for term in self.finance_terms['negative']:\n",
        "            if term in text_lower:\n",
        "                score -= 0.3\n",
        "        return score\n",
        "\n",
        "    def analyze_articles(self, articles):\n",
        "        if len(articles) < MIN_NEWS_ARTICLES:\n",
        "            print(f\"⚠️ Poucas notícias ({len(articles)}), complementando com análise de tendência...\")\n",
        "            articles.extend(self._get_fallback_news())\n",
        "        sentiment_results = []\n",
        "        print(\"\\n📰 Análise Avançada de Notícias (Google News):\")\n",
        "        for article in articles[:MAX_NEWS_ARTICLES]:\n",
        "            text = article['title']\n",
        "            vader_score = self.analyze_with_vader(text)\n",
        "            blob_score = self.analyze_with_textblob(text)\n",
        "            finance_score = self.analyze_finance_terms(text)\n",
        "            combined_score = (vader_score * 0.5 + blob_score * 0.3 + finance_score * 0.2)\n",
        "            if combined_score > 0.2:\n",
        "                emoji = \"🚀\"\n",
        "                sentiment = \"FORTEMENTE POSITIVO\"\n",
        "            elif combined_score > 0.05:\n",
        "                emoji = \"📈\"\n",
        "                sentiment = \"POSITIVO\"\n",
        "            elif combined_score < -0.2:\n",
        "                emoji = \"💥\"\n",
        "                sentiment = \"FORTEMENTE NEGATIVO\"\n",
        "            elif combined_score < -0.05:\n",
        "                emoji = \"📉\"\n",
        "                sentiment = \"NEGATIVO\"\n",
        "            else:\n",
        "                emoji = \"➖\"\n",
        "                sentiment = \"NEUTRO\"\n",
        "            print(f\"{emoji} [{sentiment}] {article['title'][:60]}... ({article['source']})\")\n",
        "            sentiment_results.append(combined_score)\n",
        "        avg_sentiment = np.mean(sentiment_results) if sentiment_results else 0\n",
        "        print(f\"\\n🔍 Sentimento Médio: {avg_sentiment:.2f} (Escala: -1 a 1)\")\n",
        "        trend = 0\n",
        "        if len(articles) > 3 and all('date' in a for a in articles):\n",
        "            sorted_articles = sorted(articles, key=lambda x: x['date'])\n",
        "            early_scores = [self.analyze_with_vader(a['title']) for a in sorted_articles[:3]]\n",
        "            late_scores = [self.analyze_with_vader(a['title']) for a in sorted_articles[-3:]]\n",
        "            trend = np.mean(late_scores) - np.mean(early_scores)\n",
        "            print(f\"📅 Tendência Temporal: {'Melhorando' if trend > 0 else 'Piorando' if trend < 0 else 'Estável'}\")\n",
        "        return {\n",
        "            'sentiment': avg_sentiment,\n",
        "            'trend': trend,\n",
        "            'recent_impact': avg_sentiment * 1.5\n",
        "        }\n",
        "\n",
        "class EnhancedStockPredictor:\n",
        "    def __init__(self):\n",
        "        self.learning_rate = LEARNING_RATE\n",
        "        self.epochs = EPOCHS\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.scaler = RobustScaler()\n",
        "        self.news_analyzer = GoogleNewsAnalyzer()\n",
        "        self.feature_cols = ['close', 'volume', 'ma_5', 'ma_20', 'volatility', 'momentum', 'news_sentiment', 'news_trend']\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        try:\n",
        "            df['returns'] = df['close'].pct_change()\n",
        "            df['ma_5'] = df['close'].rolling(5).mean()\n",
        "            df['ma_20'] = df['close'].rolling(20).mean()\n",
        "            df['volatility'] = df['returns'].rolling(VOLATILITY_WINDOW).std()\n",
        "            df['momentum'] = df['close'] - df['close'].shift(5)\n",
        "            articles = self.news_analyzer.fetch_google_news()\n",
        "            news_impact = self.news_analyzer.analyze_articles(articles)\n",
        "            df['news_sentiment'] = news_impact['sentiment']\n",
        "            df['news_trend'] = news_impact['trend']\n",
        "            df = df.dropna()\n",
        "            X = df[self.feature_cols]\n",
        "            y = df['close'].shift(-1).dropna()\n",
        "            X = X.iloc[:-1]\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "            split_idx = int(len(X) * (1 - TEST_SIZE))\n",
        "            X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "            return X_train, X_test, y_train, y_test, df\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na preparação: {str(e)}\")\n",
        "            self.feature_cols = ['close', 'volume', 'ma_5', 'ma_20', 'volatility', 'momentum']\n",
        "            return self.prepare_data(df)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.random.randn(n_features) * 0.01\n",
        "        self.bias = 0\n",
        "        best_error = float('inf')\n",
        "        for epoch in range(self.epochs):\n",
        "            y_pred = np.dot(X, self.weights) + self.bias\n",
        "            error = np.mean((y_pred - y)**2) + 0.001 * np.sum(self.weights**2)\n",
        "            if epoch > 100 and error > best_error * 0.999:\n",
        "                print(f\"✅ Convergência na época {epoch}\")\n",
        "                break\n",
        "            if error < best_error:\n",
        "                best_error = error\n",
        "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y)) + (0.002 * self.weights)\n",
        "            db = (1/n_samples) * np.sum(y_pred - y)\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "            if epoch % 500 == 0:\n",
        "                print(f\"Época {epoch}: MSE = {error:.4f}\")\n",
        "        return best_error\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        plt.figure(figsize=(18, 9))\n",
        "        plt.plot(y_test.values, label='Real', linewidth=2)\n",
        "        plt.plot(y_pred, label='Previsto', linestyle='--')\n",
        "        plt.title(f'Desempenho do Modelo (MAE: ${mae:.2f}, R²: {r2:.2%})')\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.show()\n",
        "        return {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
        "\n",
        "    def forecast(self, df, days=5):\n",
        "        try:\n",
        "            forecasts = []\n",
        "            dates = []\n",
        "            last_row = df.iloc[-1][self.feature_cols].values.reshape(1, -1)\n",
        "            current_date = df.index[-1]\n",
        "            days_added = 0\n",
        "            while days_added < days:\n",
        "                current_date += timedelta(days=1)\n",
        "                if current_date.weekday() < 5:\n",
        "                    X_scaled = self.scaler.transform(last_row)\n",
        "                    pred = self.predict(X_scaled)[0]\n",
        "                    forecasts.append(pred)\n",
        "                    dates.append(current_date)\n",
        "                    days_added += 1\n",
        "                    new_row = last_row.copy()\n",
        "                    new_row[0][0] = pred\n",
        "                    new_row[0][2] = (new_row[0][0] + last_row[0][0] * 4) / 5\n",
        "                    new_row[0][3] = (new_row[0][0] + last_row[0][0] * 19) / 20\n",
        "                    last_row = new_row\n",
        "            forecast_df = pd.DataFrame({'date': dates, 'forecast': forecasts})\n",
        "            forecast_df.set_index('date', inplace=True)\n",
        "            plt.figure(figsize=(18, 9))\n",
        "            plt.plot(df['close'].iloc[-30:], label='Histórico', marker='o')\n",
        "            plt.plot(forecast_df['forecast'], label='Previsão', color='red', linestyle='--', marker='o')\n",
        "            plt.title(f'Previsão para {SYMBOL} - Próximos {days} dias úteis')\n",
        "            plt.legend()\n",
        "            plt.grid(alpha=0.3)\n",
        "            plt.show()\n",
        "            return forecast_df\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na previsão: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def main():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"=== ANÁLISE DE {SYMBOL} COM NLP NO GOOGLE NEWS ===\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "    try:\n",
        "        print(\"📊 Baixando dados históricos...\")\n",
        "        start_time = time.time()\n",
        "        df = yf.download(SYMBOL, period=f\"{DAYS_TO_FETCH//365}y\", progress=False)\n",
        "        df = df[['Close', 'Volume']]\n",
        "        df.columns = ['close', 'volume']\n",
        "        print(f\"✅ Dados baixados - {len(df)} dias | Último preço: ${df['close'].iloc[-1]:.2f}\")\n",
        "        print(\"\\n🧠 Preparando dados com análise de notícias...\")\n",
        "        predictor = EnhancedStockPredictor()\n",
        "        X_train, X_test, y_train, y_test, df_processed = predictor.prepare_data(df)\n",
        "        print(f\"✅ Dados preparados - {len(X_train)} treino, {len(X_test)} teste\")\n",
        "        print(\"\\n🔮 Treinando modelo...\")\n",
        "        train_start = time.time()\n",
        "        final_error = predictor.train(X_train, y_train)\n",
        "        print(f\"✅ Treino concluído em {time.time()-train_start:.1f}s (MSE final: {final_error:.4f})\")\n",
        "        print(\"\\n📊 Avaliando modelo...\")\n",
        "        metrics = predictor.evaluate(X_test, y_test)\n",
        "        print(f\"\\n🔍 Resultados:\")\n",
        "        print(f\"- MAE: ${metrics['mae']:.2f}\")\n",
        "        print(f\"- RMSE: ${metrics['rmse']:.2f}\")\n",
        "        print(f\"- R²: {metrics['r2']:.2%}\")\n",
        "        print(\"\\n🔮 Gerando previsões...\")\n",
        "        forecast = predictor.forecast(df_processed)\n",
        "        if forecast is not None:\n",
        "            print(\"\\n📈 Previsões para os próximos dias úteis:\")\n",
        "            print(forecast.round(2))\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n⏹️ Execução interrompida pelo usuário\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Erro: {str(e)}\")\n",
        "    finally:\n",
        "        print(f\"\\n⏱️ Tempo total: {time.time()-start_time:.1f} segundos\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PocZaXKaIWUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}